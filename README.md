# GazeUnconstrainedPipeline

An end-to-end AI engineering pipeline for unconstrained gaze estimationâ€”from data collection to model training and evaluation. This repository showcases a complete system including multi-modal data collection, synchronized preprocessing, unified dataset loaders, multiple baseline models, and performance evaluation.

## ðŸ”§ Project Structure

```
GazeUnconstrainedPipeline/
â”œâ”€â”€ data/                # Sample data and download instructions
â”œâ”€â”€ scripts/             # Data collection and preprocessing
â”œâ”€â”€ datasets/            # Unified PyTorch Dataset class
â”œâ”€â”€ models/              # Baseline model implementations
â”œâ”€â”€ training/            # Training, evaluation, configuration
â”œâ”€â”€ notebooks/           # Analysis and visualization
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ .gitignore           # Git exclusions
â”œâ”€â”€ LICENSE              # MIT License
â””â”€â”€ README.md            # This documentation
```

## ðŸ“¦ Features

- Multi-modal gaze dataset collection pipeline (Tobii + Webcam + Screen)
- Unified Dataset for iTracker, GazeTR, AFF-Net, Gaze360, and GazeNet
- Leave-one-subject-out training strategy
- Evaluation metrics: Angular Error and Euclidean Distance
- Visualization support (e.g., gaze heatmaps)

## ðŸš€ Getting Started

```bash
# Clone the repository
git clone https://github.com/yourusername/GazeUnconstrainedPipeline.git
cd GazeUnconstrainedPipeline

# Install dependencies
pip install -r requirements.txt
```

## ðŸ§ª Training

```bash
python training/train.py --model gazeTR --config training/config.yaml
```

## ðŸ“Š Sample Results

| Model    | Angular Error (Â°) | Euclidean Error (px) |
|----------|-------------------|----------------------|
| GazeTR   | 4.57              | 48.2                 |
| iTracker | 5.21              | 62.7                 |

## ðŸ”’ Data

Only sample data is included. Full dataset available upon request:
> Contact: wen.zhou@xxx.ac.uk

## ðŸ“„ License

MIT License. See `LICENSE` for details.

## ðŸ™ Citation

If you use this project or dataset, please cite:

> Zhou et al., *GazeUnconstrained: A Dataset for Gaze Estimation in Unconstrained Environment*, 2025
